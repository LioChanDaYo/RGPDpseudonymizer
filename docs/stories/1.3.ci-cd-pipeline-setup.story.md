# Story 1.3: CI/CD Pipeline Setup

## Status

**Draft**

---

## Story

**As a** developer,
**I want** automated testing pipeline running on every commit across multiple platforms,
**so that** I can catch regressions early and ensure cross-platform compatibility throughout development.

---

## Acceptance Criteria

1. **AC1:** GitHub Actions workflow configured with test matrix: Windows 11, macOS (latest), Ubuntu 22.04.
2. **AC2:** Workflow runs on every push and pull request: install dependencies, run pytest, report coverage.
3. **AC3:** Code quality checks integrated: Black formatting verification, Ruff linting, mypy type checking.
4. **AC4:** Test execution time <5 minutes for unit tests, <15 minutes including integration tests.
5. **AC5:** Failed checks block PR merges (branch protection rules configured).
6. **AC6:** Coverage reporting integrated (codecov or similar), minimum 80% coverage threshold enforced.
7. **AC7:** CI/CD documentation created: workflow description, how to run locally, troubleshooting common failures.

---

## Tasks / Subtasks

- [ ] **Task 1: Create GitHub Actions Workflow Directory Structure** (AC: 1)
  - [ ] Create `.github/workflows/` directory in project root
  - [ ] Create `.github/ISSUE_TEMPLATE/` directory (placeholder for future issue templates)
  - [ ] Verify directory structure matches architecture specification

- [ ] **Task 2: Create Main CI Testing Workflow** (AC: 1, 2, 4)
  - [ ] Create `.github/workflows/ci.yaml` file
  - [ ] Configure workflow triggers: `on: [push, pull_request]`
  - [ ] Define test matrix with 3 operating systems: `ubuntu-22.04`, `macos-latest`, `windows-latest`
  - [ ] Define Python version matrix: `['3.9', '3.10', '3.11']` (9 total configurations)
  - [ ] Add checkout action: `actions/checkout@v4`
  - [ ] Add Python setup action: `actions/setup-python@v5` with matrix Python version
  - [ ] Install Poetry: Add step to install Poetry 1.7+
  - [ ] Install dependencies: `poetry install` (includes dev dependencies)
  - [ ] Download spaCy model: `python -m spacy download fr_core_news_lg`
  - [ ] Run pytest: `poetry run pytest --cov=gdpr_pseudonymizer --cov-report=xml --cov-report=term`
  - [ ] Upload coverage reports: Use `codecov/codecov-action@v3` or `actions/upload-artifact@v3`
  - [ ] Add timeout: Set job timeout to 30 minutes to prevent hung builds
  - [ ] Optimize for speed: Cache Poetry dependencies using `actions/cache@v3`

- [ ] **Task 3: Create Code Quality Workflow** (AC: 3)
  - [ ] Create `.github/workflows/code-quality.yaml` file
  - [ ] Configure workflow triggers: `on: [push, pull_request]`
  - [ ] Run on single OS (ubuntu-latest) for speed, Python 3.11
  - [ ] Add checkout and Python setup steps
  - [ ] Install Poetry and project dependencies
  - [ ] Add Black formatting check: `poetry run black --check gdpr_pseudonymizer/ tests/ scripts/`
  - [ ] Add Ruff linting: `poetry run ruff check gdpr_pseudonymizer/ tests/ scripts/`
  - [ ] Add mypy type checking: `poetry run mypy gdpr_pseudonymizer/`
  - [ ] Configure to fail workflow if any quality check fails
  - [ ] Add timeout: 10 minutes (quality checks are faster than tests)

- [ ] **Task 4: Configure Branch Protection Rules** (AC: 5)
  - [ ] Document branch protection configuration steps in CI/CD documentation
  - [ ] Specify required status checks: `ci (ubuntu-22.04, 3.9)`, `ci (macos-latest, 3.11)`, `ci (windows-latest, 3.11)`, `code-quality`
  - [ ] Note: Actual GitHub branch protection rule configuration requires repository admin access
  - [ ] Create step-by-step guide for repository administrators to configure protection rules
  - [ ] Include screenshots or GitHub UI navigation instructions

- [ ] **Task 5: Configure Coverage Reporting** (AC: 6)
  - [ ] Choose coverage service: Codecov (free for open-source projects)
  - [ ] Create `.codecov.yml` configuration file in project root
  - [ ] Set coverage threshold: 80% minimum (70% for Epic 1, 80% for Epic 2+)
  - [ ] Configure coverage report format: XML for Codecov upload, terminal output for logs
  - [ ] Add Codecov upload step to CI workflow: `codecov/codecov-action@v3`
  - [ ] Configure Codecov to comment on PRs with coverage changes
  - [ ] Document how to view coverage reports locally: `poetry run pytest --cov=gdpr_pseudonymizer --cov-report=html`
  - [ ] Note: Codecov integration requires repository admin to add Codecov GitHub app

- [ ] **Task 6: Create Project Configuration Files** (AC: 2, 3)
  - [ ] Create `pyproject.toml` with Poetry configuration
    - [ ] Define project metadata: name, version, description, authors, license
    - [ ] Specify Python version requirement: `^3.9`
    - [ ] Add runtime dependencies: spaCy 3.7+, typer 0.9+, rich 13.7+, PyYAML 6.0+, cryptography 41.0+, SQLAlchemy 2.0+, structlog 23.2+, markdown-it-py 3.0+
    - [ ] Add dev dependencies: pytest 7.4+, pytest-cov 4.1+, pytest-mock 3.12+, pytest-benchmark 4.0+, black 23.12+, ruff 0.1+, mypy 1.7+
    - [ ] Configure Black: line length 88, target Python 3.9
    - [ ] Configure Ruff: line length 88, select rules (F, E, W, I, N, UP)
    - [ ] Add pytest configuration section: testpaths, python_files, python_classes, python_functions
  - [ ] Create `pytest.ini` (or use pyproject.toml [tool.pytest.ini_options])
    - [ ] Set testpaths: `tests/unit tests/integration tests/performance`
    - [ ] Configure markers: `@pytest.mark.benchmark` for performance tests
    - [ ] Add coverage options: `--cov-branch` for branch coverage
  - [ ] Create `mypy.ini` (or use pyproject.toml [tool.mypy])
    - [ ] Set Python version: `python_version = "3.9"`
    - [ ] Enable strict mode: `strict = true`
    - [ ] Configure exclusions: ignore test files initially if needed
    - [ ] Ignore missing imports for third-party libraries without stubs

- [ ] **Task 7: Test CI/CD Pipeline Locally** (AC: 2, 3, 4)
  - [ ] Install Poetry locally: `pip install poetry`
  - [ ] Run `poetry install` to verify dependency resolution
  - [ ] Run Black check locally: `poetry run black --check .`
  - [ ] Run Ruff check locally: `poetry run ruff check .`
  - [ ] Run mypy check locally: `poetry run mypy gdpr_pseudonymizer/`
  - [ ] Run pytest locally: `poetry run pytest --cov=gdpr_pseudonymizer`
  - [ ] Measure test execution time (should be <5 min for unit tests)
  - [ ] Fix any errors or configuration issues discovered
  - [ ] Verify spaCy model download works: `python -m spacy download fr_core_news_lg`

- [ ] **Task 8: Create Initial GitHub Actions Test PR** (AC: 1, 2, 3, 4)
  - [ ] Commit all CI/CD configuration files to a feature branch
  - [ ] Create pull request to trigger GitHub Actions workflows
  - [ ] Verify workflows execute on all matrix configurations (9 OS/Python combos)
  - [ ] Check workflow execution time: unit tests <5 min, code quality <2 min
  - [ ] Review workflow logs for errors or warnings
  - [ ] Verify coverage reports are generated and uploaded
  - [ ] Fix any failures discovered in CI environment (path issues, missing dependencies, etc.)
  - [ ] Iterate until all workflows pass successfully

- [ ] **Task 9: Create CI/CD Documentation** (AC: 7)
  - [ ] Create `docs/ci-cd.md` file
  - [ ] Document CI/CD architecture:
    - [ ] Workflow file locations and purposes
    - [ ] Test matrix strategy (OS and Python versions)
    - [ ] Quality checks performed (Black, Ruff, mypy)
    - [ ] Coverage requirements and reporting
  - [ ] Document how to run checks locally:
    - [ ] Poetry installation instructions
    - [ ] Command reference for each quality check
    - [ ] How to run pytest with coverage
    - [ ] How to view coverage HTML reports
  - [ ] Document common CI failures and troubleshooting:
    - [ ] Poetry dependency resolution failures
    - [ ] spaCy model download issues (large file, network timeouts)
    - [ ] Platform-specific test failures (path separators, line endings)
    - [ ] Type checking errors (mypy configuration)
    - [ ] Coverage threshold failures (how to increase coverage)
  - [ ] Document branch protection rules:
    - [ ] Which status checks are required
    - [ ] How to configure branch protection (admin guide)
    - [ ] How to merge PRs with passing checks
  - [ ] Add workflow badges to README.md:
    - [ ] CI status badge: `[![CI](https://github.com/org/repo/actions/workflows/ci.yaml/badge.svg)](https://github.com/org/repo/actions/workflows/ci.yaml)`
    - [ ] Code quality badge: `[![Code Quality](https://github.com/org/repo/actions/workflows/code-quality.yaml/badge.svg)](https://github.com/org/repo/actions/workflows/code-quality.yaml)`
    - [ ] Coverage badge: `[![codecov](https://codecov.io/gh/org/repo/branch/main/graph/badge.svg)](https://codecov.io/gh/org/repo)`

- [ ] **Task 10: Unit Tests for CI/CD Configuration** (AC: 2, 3)
  - [ ] Create `tests/unit/test_project_config.py`
  - [ ] Test pyproject.toml parsing: Verify file is valid TOML format
  - [ ] Test dependency specifications: Verify all required dependencies are listed
  - [ ] Test Python version compatibility: Verify project supports Python 3.9+
  - [ ] Test import structure: Verify all project modules can be imported
  - [ ] Add smoke tests: Basic "can import main modules" tests to catch configuration errors early

---

## Dev Notes

### Previous Story Insights

**From Story 1.1 (Expand Test Corpus):**
- Test corpus location: `tests/test_corpus/` with 25 documents and ground truth annotations
- Test structure established: `tests/unit/` directory exists with initial NLP detector tests
- Benchmark script location: `scripts/benchmark_nlp.py` (functional and tested)

**From Story 1.2 (NLP Benchmark):**
- spaCy selected as NLP library (spaCy 3.8.0, fr_core_news_lg model)
- Stanza also installed for comparison (may need both in dev dependencies for benchmarking)
- Large NLP models require download step in CI (~571MB for fr_core_news_lg)
- Existing unit tests: `tests/unit/test_spacy_detector.py`, `tests/unit/test_stanza_detector.py`, `tests/unit/test_benchmark_nlp.py`
- CI must handle model download: `python -m spacy download fr_core_news_lg` (can be slow, needs caching)

**Key Takeaways for CI/CD:**
- NLP model download is CRITICAL CI step that can fail (large file, network issues)
- Model caching across CI runs will significantly improve build speed
- Tests currently exist only in `tests/unit/` - integration tests will be added in Story 1.4+
- Coverage baseline starting from Story 1.2: likely 60-70%, target 70% for Epic 1

---

### Project Structure Context

**CI/CD Configuration Locations:** [Source: architecture/12-unified-project-structure.md]
```
gdpr-pseudonymizer/
├── .github/
│   ├── workflows/
│   │   ├── ci.yaml                    # Main CI testing workflow
│   │   └── release.yaml               # PyPI publishing (Epic 4)
│   └── ISSUE_TEMPLATE/                # GitHub issue templates (future)
├── pyproject.toml                     # Poetry config, Black/Ruff/mypy settings
├── pytest.ini                         # pytest configuration (or in pyproject.toml)
├── mypy.ini                           # mypy configuration (or in pyproject.toml)
└── .codecov.yml                       # Coverage reporting config
```

**Note:** `.github/` directory does not currently exist - will be created in Task 1.

**Test Directory Structure:** [Source: architecture/12-unified-project-structure.md]
```
tests/
├── unit/                              # Unit tests (isolated component tests)
├── integration/                       # Integration tests (multi-component workflows)
├── performance/                       # Performance tests (NFR validation)
└── test_corpus/                       # 25-document benchmark corpus
```

**Currently Exists:** `tests/unit/` with 3 test files, `tests/test_corpus/` with benchmark data.

**To Be Created in Future Stories:** `tests/integration/`, `tests/performance/`

---

### Tech Stack Requirements

**CI/CD Platform:** GitHub Actions [Source: architecture/3-tech-stack.md#ci/cd]
- Free for public repositories
- Excellent OS matrix support (Windows/Mac/Linux)
- PyPI publishing integration (for release workflow in Epic 4)

**Dependency Management:** Poetry 1.7+ [Source: architecture/3-tech-stack.md#dependency-mgmt]
- Modern lockfile for reproducible builds (poetry.lock)
- PEP 621 compliant, better resolver than pip
- Simplifies dependency specification in pyproject.toml

**Python Version:** Python 3.9+ [Source: architecture/3-tech-stack.md#runtime]
- Test matrix must cover Python 3.9, 3.10, 3.11
- Python 3.9 EOL Oct 2025, provides safe window for MVP
- Use `actions/setup-python@v5` in GitHub Actions

**Code Formatter:** Black 23.12+ [Source: architecture/3-tech-stack.md#code-formatter]
- Uncompromising formatter, eliminates style debates
- Run in check mode in CI: `black --check .`
- Industry standard for Python projects

**Linter:** Ruff 0.1+ [Source: architecture/3-tech-stack.md#linter]
- 10-100x faster than Pylint/Flake8
- Compatible with Black (no formatting conflicts)
- Replaces multiple tools (Flake8, isort, pyupgrade)

**Type Checker:** mypy 1.7+ [Source: architecture/3-tech-stack.md#type-checker]
- Static type checking to catch type errors before runtime
- Integrates with Typer/SQLAlchemy types
- Enforce type hints across codebase

**Testing Framework:** pytest 7.4+ [Source: architecture/3-tech-stack.md#testing-framework]
- Fixture system, parametrization, excellent plugin ecosystem
- Industry standard for Python testing

**Test Coverage:** pytest-cov 4.1+ [Source: architecture/3-tech-stack.md#test-coverage]
- Coverage.py integration
- Target: ≥80% coverage (70% for Epic 1, 80% for Epic 2+)
- Branch coverage tracking with `--cov-branch`

**Performance Testing:** pytest-benchmark 4.0+ [Source: architecture/3-tech-stack.md#performance-testing]
- Measure processing time, track regressions
- Validate NFR1-2 performance targets (<30s single-doc, <30min batch)
- Not used in Epic 1, but dependencies should be installed

**NLP Dependencies:** [Source: architecture/3-tech-stack.md#nlp-library]
- spaCy 3.7+ (tested with 3.8.0)
- fr_core_news_lg model 3.8.0 (~571MB, downloaded post-install)
- Stanza 1.7+ (for benchmarking, may be dev dependency only)

**Runtime Dependencies:** [Source: architecture/3-tech-stack.md]
- Typer 0.9+ (CLI framework)
- rich 13.7+ (progress bars, CLI UX)
- PyYAML 6.0+ (config file parsing)
- cryptography 41.0+ (Fernet encryption)
- SQLAlchemy 2.0+ (ORM)
- structlog 23.2+ (structured logging)
- markdown-it-py 3.0+ (markdown parsing)
- pathlib (stdlib, no explicit dependency)

---

### Testing Standards

**Test Coverage Targets:** [Source: architecture/16-testing-strategy.md#test-coverage-targets]
- Epic 1: 70% coverage target
- Epic 2: 80% coverage target
- Epic 3-4: 85% coverage target (maintain)

**Testing Pyramid:** [Source: architecture/16-testing-strategy.md#testing-pyramid]
- Unit Tests: 75% (~225 tests by Epic 4)
- Integration Tests: 20% (~60 tests by Epic 4)
- E2E Tests: 5% (~15 tests by Epic 4)

**Epic 1 Focus:** Primarily unit tests, integration tests start in Story 1.4+.

**Performance Test Requirements:** [Source: architecture/16-testing-strategy.md#performance-tests]
- Use pytest-benchmark for performance validation
- NFR1: Process 2-5K word document in <30 seconds
- NFR2: Batch process 10-100 documents in <30 minutes
- Performance tests added in Epic 2-3, not Epic 1

**Test File Naming:** [Source: architecture/16-testing-strategy.md]
- Unit tests: `tests/unit/test_<module_name>.py`
- Integration tests: `tests/integration/test_<workflow_name>.py`
- Performance tests: `tests/performance/test_<performance_aspect>.py`

---

### Coding Standards

**Import Rules:** [Source: architecture/19-coding-standards.md#critical-rules]
- ALWAYS use absolute imports: `from gdpr_pseudonymizer.data.repositories import MappingRepository`
- NEVER use relative imports: `from ..data.repositories import MappingRepository`

**Type Hints:** [Source: architecture/19-coding-standards.md#critical-rules]
- All public functions MUST have type hints
- mypy will enforce this in CI

**Logging:** [Source: architecture/19-coding-standards.md#critical-rules]
- NEVER log sensitive data (entity text, user names, etc.)
- Use structured logging with context: `logger.info("entity_detected", entity_type="PERSON", confidence=0.92)`

**Naming Conventions:** [Source: architecture/19-coding-standards.md#naming-conventions]
- Modules: snake_case (`entity_detector.py`)
- Classes: PascalCase (`EntityDetector`)
- Functions: snake_case (`detect_entities()`)
- Constants: UPPER_SNAKE_CASE (`PBKDF2_ITERATIONS`)

---

### Development Workflow

**Local Development Commands:** [Source: architecture/13-development-workflow.md#development-commands]

**Code Quality:**
```bash
poetry run black gdpr_pseudonymizer/ tests/
poetry run ruff gdpr_pseudonymizer/ tests/
poetry run mypy gdpr_pseudonymizer/
```

**Testing:**
```bash
poetry run pytest                      # All tests
poetry run pytest tests/unit/ -v      # Unit tests only
poetry run pytest --cov=gdpr_pseudonymizer --cov-report=html  # With HTML coverage report
```

**Performance Tests:**
```bash
poetry run pytest tests/performance/ --benchmark-only
```

**NLP Model Download:**
```bash
python -m spacy download fr_core_news_lg
```

**Git Workflow:** [Source: architecture/13-development-workflow.md#git-workflow]

**Branch Naming:**
- `feature/short-description` - New features
- `bugfix/short-description` - Bug fixes
- `hotfix/short-description` - Urgent fixes

**Commit Message Format:**
```
<type>: <short summary> (max 50 chars)

<detailed description> (wrap at 72 chars)

Relates to: Epic 1, Story 1.3
```

**Commit Types:** `feat`, `fix`, `docs`, `test`, `refactor`, `perf`, `chore`

---

### Deployment Architecture

**Deployment Model:** User-installed package (not SaaS) [Source: architecture/14-deployment-architecture.md#deployment-strategy]

**Distribution Method:** PyPI (Python Package Index) [Source: architecture/14-deployment-architecture.md#package-distribution]

**Installation Command:**
```bash
pip install gdpr-pseudonymizer
```

**Build Process:** [Source: architecture/14-deployment-architecture.md#package-distribution]
```bash
poetry build
# Output: dist/gdpr_pseudonymizer-1.0.0-py3-none-any.whl
#         dist/gdpr_pseudonymizer-1.0.0.tar.gz
```

**Publishing:** [Source: architecture/14-deployment-architecture.md#package-distribution]
```bash
poetry publish  # To PyPI (Epic 4 - release workflow)
```

**CI/CD Test Matrix:** [Source: architecture/14-deployment-architecture.md#ci/cd-pipeline]
- Operating Systems: Ubuntu 22.04, macOS (latest), Windows (latest)
- Python Versions: 3.9, 3.10, 3.11
- Total Configurations: 9 (3 OS × 3 Python versions)

**GitHub Actions Workflow Example:** [Source: architecture/14-deployment-architecture.md#ci/cd-pipeline]
```yaml
name: CI - Test Matrix

on: [push, pull_request]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-22.04, macos-latest, windows-latest]
        python-version: ['3.9', '3.10', '3.11']

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: poetry install
      - name: Run tests
        run: poetry run pytest --cov=gdpr_pseudonymizer
```

---

### CI/CD Performance Requirements

**Test Execution Time Targets:** [Source: Epic 1, Story 1.3 AC4]
- Unit tests: <5 minutes
- Integration tests (when added): <15 minutes total (unit + integration)
- Code quality checks: <2 minutes (Black, Ruff, mypy run fast)

**Optimization Strategies:**
1. **Cache Poetry dependencies:** Use `actions/cache@v3` to cache `~/.cache/pypoetry` and `~/.local/share/pypoetry`
2. **Cache spaCy models:** Cache `~/.spacy` or model download location to avoid re-downloading 571MB model on every run
3. **Parallel matrix execution:** GitHub Actions runs matrix jobs in parallel (9 jobs run simultaneously if runners available)
4. **Separate quality checks:** Run Black/Ruff/mypy on single OS (ubuntu-latest) instead of full matrix (3x faster)
5. **Conditional workflows:** Code quality workflow can skip if only docs changed (future optimization)

**Common CI Failures to Handle:**
1. **spaCy model download timeout:** 571MB download can fail on slow networks, add retry logic or pre-cached model
2. **Platform-specific path issues:** Windows uses backslashes, macOS/Linux use forward slashes, use `pathlib` everywhere
3. **Poetry dependency resolution:** Lock file conflicts, dependency version incompatibilities
4. **Type checking failures:** mypy strict mode can be challenging initially, may need to relax strictness for Epic 1
5. **Coverage threshold failures:** New code without tests will fail coverage checks

---

### Testing

**Test File Locations:** [Source: architecture/16-testing-strategy.md]
- Unit tests: `tests/unit/test_*.py`
- Integration tests: `tests/integration/test_*.py` (Story 1.4+)
- Performance tests: `tests/performance/test_*.py` (Epic 2+)

**Testing Frameworks:** [Source: architecture/3-tech-stack.md]
- pytest 7.4+ for test execution
- pytest-cov 4.1+ for coverage measurement
- pytest-mock 3.12+ for mocking
- pytest-benchmark 4.0+ for performance tests

**Testing Standards:** [Source: architecture/16-testing-strategy.md]

**Unit Test Coverage Target:** 90-100% for core business logic

**Example Unit Test Pattern:**
```python
def test_encrypt_decrypt_roundtrip():
    service = EncryptionService("password", os.urandom(32))
    plaintext = "Sensitive Data"

    encrypted = service.encrypt(plaintext)
    assert encrypted != plaintext

    decrypted = service.decrypt(encrypted)
    assert decrypted == plaintext
```

**Integration Test Coverage Target:** 80% of integration paths

**Example Integration Test Pattern:**
```python
def test_reprocess_document_reuses_mappings(test_db, tmp_path):
    """Test FR19: Idempotent processing."""
    orchestrator = create_orchestrator(test_db)

    # First processing
    result1 = orchestrator.process_document("input.txt", "output1.txt")
    assert result1.entities_detected == 2

    # Second processing (same document)
    result2 = orchestrator.process_document("input.txt", "output2.txt")
    assert result2.entities_reused == 2
    assert result2.entities_new == 0
```

**CI-Specific Test Requirements:**

1. **Configuration Validation Tests:**
   - Test pyproject.toml is valid TOML
   - Test all required dependencies are listed
   - Test Python version compatibility

2. **Import Smoke Tests:**
   - Test all project modules can be imported
   - Catch early configuration errors in CI

3. **Platform-Specific Tests:**
   - Test file path handling works on Windows/Mac/Linux
   - Test line ending handling (CRLF vs LF)

4. **Model Loading Tests:**
   - Test spaCy model loads successfully
   - Test model download detection (skip download if already present)

**Test Execution in CI:**
```bash
# Run all tests with coverage
poetry run pytest --cov=gdpr_pseudonymizer --cov-report=xml --cov-report=term

# Run only unit tests (faster)
poetry run pytest tests/unit/ -v

# Run with verbose output for debugging CI failures
poetry run pytest -v --tb=short
```

**Coverage Reporting:**
- Generate XML report for Codecov: `--cov-report=xml`
- Generate terminal output for CI logs: `--cov-report=term`
- Generate HTML report for local viewing: `--cov-report=html` (creates `htmlcov/` directory)

**Branch Coverage:**
- Enable branch coverage: `pytest --cov-branch`
- Tracks whether both branches of if/else statements are tested
- More rigorous than line coverage alone

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-16 | 1.0 | Story created from Epic 1 requirements | BMAD System |

---

## Dev Agent Record

*This section will be populated by the development agent during implementation.*

### Agent Model Used

*To be filled by dev agent*

### Debug Log References

*To be filled by dev agent*

### Completion Notes List

*To be filled by dev agent*

### File List

*To be filled by dev agent*

---

## QA Results

*This section will be populated by the QA agent after story completion.*
