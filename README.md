# GDPR Pseudonymizer

**AI-Assisted Pseudonymization for French Documents with Human Verification**

Transform sensitive French documents for safe AI analysis with local processing, mandatory human review, and GDPR compliance.

---

## ğŸ¯ Overview

GDPR Pseudonymizer is a **privacy-first CLI tool** that combines AI efficiency with human accuracy to pseudonymize French text documents. Unlike fully automatic tools or cloud services, we prioritize **zero false negatives** and **legal defensibility** through mandatory validation workflows.

**Perfect for:**
- ğŸ›ï¸ **Privacy-conscious organizations** needing GDPR-compliant AI analysis
- ğŸ“ **Academic researchers** with ethics board requirements
- âš–ï¸ **Legal/HR teams** requiring defensible pseudonymization
- ğŸ¤– **LLM users** who want to analyze confidential documents safely

---

## âœ¨ Key Features

### ğŸ”’ **Privacy-First Architecture**
- âœ… **100% local processing** - Your data never leaves your machine
- âœ… **No cloud dependencies** - Works completely offline after installation
- âœ… **Encrypted mapping tables** - Reversible pseudonymization with passphrase protection
- âœ… **Zero telemetry** - No analytics, crash reporting, or external communication

### ğŸ¤ **AI + Human Verification**
- âœ… **Hybrid detection** - AI pre-detects 40-50% of entities (NLP + regex patterns)
- âœ… **Mandatory validation** - You review and confirm all entities (ensures 100% accuracy)
- âœ… **Fast validation UI** - Rich CLI interface with keyboard shortcuts, <2 min per document
- âœ… **Smart workflow** - Entity-by-type grouping (PERSON â†’ ORG â†’ LOCATION) with context display
- âœ… **Batch actions** - Confirm/reject multiple entities efficiently

### ğŸ“Š **Batch Processing**
- âœ… **Consistent pseudonyms** - Same entity = same pseudonym across 10-100+ documents
- âœ… **Compositional matching** - "Marie Dubois" â†’ "Leia Organa", "Marie" alone â†’ "Leia"
- âœ… **Smart name handling** - Title stripping ("Dr. Marie Dubois" = "Marie Dubois"), compound names ("Jean-Pierre" treated as atomic)
- âœ… **50%+ time savings** vs manual redaction (AI pre-detection + validation)

### ğŸ­ **Themed Pseudonyms**
- âœ… **Readable output** - Star Wars, LOTR, or generic French names
- âœ… **Maintains context** - LLM analysis preserves â‰¥80% document utility
- âœ… **Gender-preserving** - When NER provides gender classification

---

## ğŸš€ Quick Start

**Status:** ğŸš§ **Pre-MVP Development** (Week 1/14 - Epic 1 in progress)

### Current Development Stage

We're actively developing v1.0 MVP with an **AI-assisted approach**:
- âœ… **Epic 1 Complete (9/9 stories):** Foundation & NLP validation operational
  - Story 1.7: Validation UI with rich CLI interface
  - Story 1.8: Hybrid detection (35.3% improvement, +52.2% PERSON detection)
  - Story 1.9: Entity deduplication (66% time reduction for large docs)
- ğŸ”„ **Week 6-10 (Current):** Epic 2 - Core pseudonymization engine
  - Story 2.0.1: Integration tests âœ… (19 tests, 80.49% coverage)
  - Story 2.1: Pseudonym library system âœ… (3 themed libraries, 90.76% coverage)
  - Story 2.2: Compositional pseudonymization logic âœ… (37 tests, 94% coverage, QA score 95/100)
  - Story 2.3: French name preprocessing (titles + compounds) âœ… (53 tests, 94.64% coverage, QA score 100/100)
- ğŸ“… **Week 11-14:** CLI polish, batch processing, launch prep
- ğŸ¯ **MVP Launch:** Week 14 (estimated Q2 2026)

### Realistic Expectations for v1.0

**What v1.0 delivers:**
- ğŸ¤– **AI-assisted detection** - Hybrid NLP + regex detects ~40-50% of entities automatically
- âœ… **Mandatory human verification** - You review and confirm all entities (2-3 min per document)
- ğŸ”’ **100% accuracy guarantee** - Human validation ensures zero false negatives
- âš¡ **50%+ faster than manual** - Pre-detection saves time vs pure manual redaction

**What v1.0 does NOT deliver:**
- âŒ Fully automatic "set and forget" processing
- âŒ 85%+ AI accuracy (current: 40-50% with hybrid approach)
- âŒ Optional validation mode (validation is mandatory)

### Roadmap

**v1.0 (MVP - Week 14):** AI-assisted with mandatory validation
- Target: Privacy-conscious early adopters who value human oversight

**v1.1 (Q2 2026):** Semi-automatic with optional validation
- Fine-tuned model: 70-85% F1 accuracy
- Optional `--no-validate` flag for high-confidence workflows

**v2.0 (Future):** Fully automatic with confidence thresholds
- 85%+ F1 accuracy
- Confidence-based auto-processing

---

## âš™ï¸ Installation (MVP Development)

**Current status:** Development version only (not ready for production use)

### Prerequisites
- Python 3.9-3.11 (validated in CI/CD, Python 3.12-3.13 support planned, Python 3.14+ not supported due to spaCy compatibility)
- Poetry 1.7+

### Quick Install

```bash
# Clone repository
git clone https://github.com/LioChanDaYo/RGPDpseudonymizer.git
cd RGPDpseudonymizer

# Install dependencies
poetry install

# Install spaCy French model (required - 571MB download)
poetry run python scripts/install_spacy_model.py
```

### Verify Installation

```bash
# Run CLI
poetry run gdpr-pseudo --help

# Test on sample document
echo "Marie Dubois travaille Ã  Paris pour Acme SA." > test.txt
poetry run gdpr-pseudo process test.txt output.txt
```

Expected output: "Leia Organa travaille Ã  Coruscant pour Rebel Alliance."

---

## ğŸ“– Documentation

**For Users:**
- ğŸ“˜ [Installation Guide](docs/installation.md) *(Coming in Epic 3)*
- ğŸ“— [Usage Tutorial](docs/tutorial.md) *(Coming in Epic 3)*
- ğŸ“• [Methodology & Academic Citation](docs/methodology.md) *(Coming in Epic 4)*
- â“ [FAQ](docs/faq.md) *(Coming in Epic 4)*

**For Developers:**
- ğŸ—ï¸ [Architecture Documentation](docs/architecture/) *(In progress)*
- ğŸ“Š [NLP Benchmark Report](docs/nlp-benchmark-report.md) *(Complete)*
- ğŸ¯ [Product Requirements (PRD)](docs/.ignore/prd.md) *(v2.0 - Updated 2026-01-16)*

**For Stakeholders:**
- ğŸ¨ [Positioning & Messaging](docs/positioning-messaging-v2-assisted.md)
- ğŸ“‹ [Deliverables Summary](docs/DELIVERABLES-SUMMARY-2026-01-16.md)

---

## ğŸ”¬ Technical Details

### NLP Library Selection (Story 1.2 - Completed)

After comprehensive benchmarking on 25 French interview/business documents (1,855 entities):

| Library | F1 Score | Precision | Recall | Decision |
|---------|----------|-----------|--------|----------|
| **spaCy** `fr_core_news_lg` | **29.5%** | 27.0% | 32.7% | âœ… **Selected** |
| **Stanza** `fr_default` | 11.9% | 10.3% | 14.1% | âŒ Rejected |

**Why both failed 85% target:**
- Pre-trained models optimized for news text (not interview/business docs)
- Domain-specific language patterns (conversational, mixed registers)
- ORG detection catastrophic (3.8% precision = 96% false positives)

**Approved Solution:**
- âœ… **Hybrid approach** (NLP + regex) targets 40-50% F1
- âœ… **Mandatory validation** ensures 100% final accuracy
- ğŸ“… **Fine-tuning** deferred to v1.1 (70-85% F1 target)

See full analysis: [docs/nlp-benchmark-report.md](docs/nlp-benchmark-report.md)

### Validation Workflow (Story 1.7 - Complete)

The validation UI provides an intuitive keyboard-driven interface for reviewing detected entities:

**Features:**
- âœ… **Entity-by-type grouping** - Review PERSON â†’ ORG â†’ LOCATION in logical order
- âœ… **Context display** - See 10 words before/after each entity with highlighting
- âœ… **Confidence scores** - Color-coded confidence from spaCy NER (green >80%, yellow 60-80%, red <60%)
- âœ… **Keyboard shortcuts** - Single-key actions: [Space] Confirm, [R] Reject, [E] Modify, [A] Add, [C] Change pseudonym
- âœ… **Batch operations** - Accept/reject all entities of a type at once (Shift+A/R)
- âœ… **Help overlay** - Press [H] for full command reference
- âœ… **Performance** - <2 minutes for typical 20-30 entity documents

**Workflow Steps:**
1. Summary screen (entity counts by type)
2. Review entities by type with context
3. Flag ambiguous entities for careful review
4. Final confirmation with summary of changes
5. Process document with validated entities

**Deduplication Feature (Story 1.9):** Duplicate entities grouped together - validate once, apply to all occurrences (66% time reduction for large docs)

---

### Technology Stack

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Runtime** | Python | 3.9-3.11 | Validated baseline (3.12-3.13 planned, 3.14+ not supported) |
| **NLP Library** | spaCy | 3.8.0 | French entity detection (fr_core_news_lg) |
| **CLI Framework** | Typer | 0.9+ | Command-line interface |
| **Database** | SQLite | 3.35+ | Local mapping table storage |
| **Encryption** | cryptography (Fernet) | 41.0+ | Symmetric encryption for mappings |
| **Validation UI** | rich | 13.7+ | Interactive CLI entity review |
| **Keyboard Input** | readchar | 4.2+ | Single-keypress capture for validation UI |
| **Testing** | pytest | 7.4+ | Unit & integration testing |
| **CI/CD** | GitHub Actions | N/A | Automated testing (Windows/Mac/Linux) |

---

## ğŸ¤” Why AI-Assisted Instead of Automatic?

**Short answer:** Privacy and compliance require human oversight.

**Long answer:**
1. **GDPR defensibility** - Human verification provides legal audit trail
2. **Zero false negatives** - AI misses entities, humans catch them (100% coverage)
3. **Current NLP limitations** - French models on interview/business docs: 29.5% F1 out-of-box
4. **Better than alternatives:**
   - âœ… **vs Manual redaction:** 50%+ faster (AI pre-detection)
   - âœ… **vs Cloud services:** 100% local processing (no data leakage)
   - âœ… **vs Fully automatic tools:** 100% accuracy (human verification)

**User Perspective:**
> "I WANT human review for compliance reasons. The AI saves me time by pre-flagging entities, but I control the final decision." - Compliance Officer

---

## ğŸ¯ Use Cases

### 1. **Research Ethics Compliance**
**Scenario:** Academic researcher with 50 interview transcripts needing IRB approval

**Without GDPR Pseudonymizer:**
- âŒ Manual redaction: 16-25 hours
- âŒ Destroys document coherence for analysis
- âŒ Error-prone (human fatigue)

**With GDPR Pseudonymizer:**
- âœ… AI pre-detection: ~30 min processing
- âœ… Human validation: ~90 min review (50 docs Ã— ~2 min each)
- âœ… Total: **2-3 hours** (85%+ time savings)
- âœ… Audit trail for ethics board

---

### 2. **HR Document Analysis**
**Scenario:** HR team analyzing employee feedback with ChatGPT

**Without GDPR Pseudonymizer:**
- âŒ Can't use ChatGPT (GDPR violation - employee names exposed)
- âŒ Manual analysis only (slow, limited insights)

**With GDPR Pseudonymizer:**
- âœ… Pseudonymize locally (employee names â†’ pseudonyms)
- âœ… Send to ChatGPT safely (no personal data exposed)
- âœ… Get AI insights while staying GDPR-compliant

---

### 3. **Legal Document Preparation**
**Scenario:** Law firm preparing case materials for AI legal research

**Without GDPR Pseudonymizer:**
- âŒ Cloud pseudonymization service (third-party risk)
- âŒ Manual redaction (expensive billable hours)

**With GDPR Pseudonymizer:**
- âœ… 100% local processing (client confidentiality)
- âœ… Human-verified accuracy (legal defensibility)
- âœ… Reversible mappings (can de-pseudonymize if needed)

---

## âš–ï¸ GDPR Compliance

### How GDPR Pseudonymizer Supports Compliance

| GDPR Requirement | Implementation |
|------------------|----------------|
| **Art. 25 - Data Protection by Design** | Local processing, no cloud dependencies, encrypted storage |
| **Art. 30 - Processing Records** | Audit logs capture all operations, timestamps, model versions |
| **Art. 32 - Security Measures** | AES-128-CBC encryption (Fernet), passphrase-protected, secure deletion |
| **Art. 35 - Privacy Impact Assessment** | Transparent methodology, cite-able approach for DPIA documentation |
| **Recital 26 - Pseudonymization** | Consistent pseudonym mapping, reversibility with passphrase |

### What Pseudonymization Means (Legally)

**According to GDPR Article 4(5):**
> "Pseudonymization means the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject **without the use of additional information**, provided that such additional information is kept separately."

**GDPR Pseudonymizer approach:**
- âœ… **Personal data replaced:** Names, locations, organizations â†’ pseudonyms
- âœ… **Separate storage:** Mapping table encrypted with passphrase (separate from documents)
- âœ… **Reversibility:** Authorized users can de-pseudonymize with passphrase
- âš ï¸ **Note:** Pseudonymization reduces risk but **does NOT make data anonymous**

**Recommendation:** Consult your Data Protection Officer (DPO) for specific compliance guidance.

---

## ğŸ› ï¸ Development Status

**Current Epic:** Epic 1 - Foundation & NLP Validation (Week 1-5/14)

### Completed âœ…
- âœ… **Story 0.1-0.2:** Test corpus (25 docs, 1,855 entities) + dev environment
- âœ… **Story 1.1:** Expanded test corpus with ground truth annotations
- âœ… **Story 1.2:** NLP benchmark (spaCy selected, contingency plan approved)
- âœ… **Story 1.3:** CI/CD pipeline setup (GitHub Actions)
- âœ… **Story 1.4:** Project foundation & module structure
- âœ… **Story 1.5:** Walking skeleton - basic process command (48 tests passing)
- âœ… **Story 1.6:** NLP integration with spaCy `fr_core_news_lg` (QA gate: PASS)
- âœ… **Story 1.7:** Validation UI implementation with rich library (QA gate: PASS)
- âœ… **Story 1.8:** Hybrid detection strategy (NLP + regex) - 35.3% improvement, 52.2% PERSON detection (QA gate: PASS)
- âœ… **Story 1.9:** Entity deduplication for validation UI - 66% time reduction for large docs (QA gate: PASS)
- âœ… **Story 2.0.1:** Integration tests for validation workflow - 19 tests, 80.49% coverage, all quality gates pass (QA gate: PASS)
- âœ… **Story 2.1:** Pseudonym library system - 3 themed libraries (neutral, Star Wars, LOTR), gender-matching, exhaustion detection, 36 tests, 90.76% coverage (QA gate: PASS, Score: 98/100)
- âœ… **Story 2.2:** Compositional pseudonymization logic - Component-based matching ("Marie Dubois" â†’ "Leia Organa", "Marie" â†’ "Leia"), 37 tests, 94% coverage (QA gate: PASS, Score: 95/100)
- âœ… **Story 2.3:** French name preprocessing (titles + compounds) - Title stripping ("Dr. Marie Dubois" â†’ "Marie Dubois"), compound names ("Jean-Pierre" treated as atomic), simple pseudonyms for compounds, 53 tests (31 unit + 15 unit + 7 integration), 94.64% coverage (QA gate: PASS, Score: 100/100)

### In Progress ğŸ”„
- ğŸ“… **Epic 2 (Week 6-10):** Core pseudonymization engine

### Upcoming ğŸ“…
- **Epic 3 (Week 11-13):** CLI polish & batch processing
- **Epic 4 (Week 14):** Launch readiness & LLM validation

---

## ğŸ¤ Contributing

**Status:** ğŸš§ Pre-release development - Not yet accepting contributions

Once we reach v1.0 MVP (Week 14), we'll welcome:
- ğŸ› Bug reports
- ğŸ“ Documentation improvements
- ğŸŒ Translations (English, Spanish, German)
- ğŸ’¡ Feature suggestions

**For now:** Follow development progress via [GitHub Issues](https://github.com/yourusername/RGPDpseudonymizer/issues) and [Discussions](https://github.com/yourusername/RGPDpseudonymizer/discussions).

---

## ğŸ“§ Contact & Support

**Project Lead:** Lionel Deveaux - [@LioChanDaYo](https://github.com/LioChanDaYo)

**For questions:**
- ğŸ’¬ [GitHub Discussions](https://github.com/yourusername/RGPDpseudonymizer/discussions) - General questions, use cases
- ğŸ› [GitHub Issues](https://github.com/yourusername/RGPDpseudonymizer/issues) - Bug reports (post-launch)
- ğŸ“§ Email: [project-email@example.com](mailto:project-email@example.com) - Private inquiries

---

## ğŸ“œ License

**TBD** - Will be announced before v1.0 MVP launch (Week 14)

Likely: MIT or Apache 2.0 (open-source, permissive)

---

## ğŸ™ Acknowledgments

**Built with:**
- [spaCy](https://spacy.io/) - Industrial-strength NLP library
- [Typer](https://typer.tiangolo.com/) - Modern CLI framework
- [rich](https://rich.readthedocs.io/) - Beautiful CLI formatting

**Inspired by:**
- GDPR privacy-by-design principles
- Academic research ethics requirements
- Real-world need for safe AI document analysis

**Methodology:**
- Developed using [BMAD-METHODâ„¢](https://bmad.ai) framework
- Interactive elicitation and multi-perspective validation

---

## âš ï¸ Disclaimer

**GDPR Pseudonymizer is a tool to assist with GDPR compliance. It does NOT provide legal advice.**

**Important notes:**
- âš ï¸ Pseudonymization reduces risk but is NOT anonymization
- âš ï¸ You remain the data controller under GDPR
- âš ï¸ Consult your DPO or legal counsel for compliance guidance
- âš ï¸ Human validation is MANDATORY - do not skip review steps
- âš ï¸ Test thoroughly before production use

**v1.0 MVP limitations:**
- AI detection: 40-50% baseline (not 85%+)
- Validation required for ALL documents (not optional)
- French language only (English, Spanish, etc. in future versions)
- Text formats only (.txt, .md - no PDF/DOCX in v1.0)

---

## ğŸ§ª Testing

### Running Tests

The project includes comprehensive unit and integration tests covering the validation workflow, NLP detection, and core functionality.

**Note for Windows users:** Due to known spaCy access violations on Windows ([spaCy issue #12659](https://github.com/explosion/spaCy/issues/12659)), Windows CI runs non-spaCy tests only. Full test suite runs on Linux/macOS.

**Run all tests:**
```bash
poetry run pytest -v
```

**Run only unit tests:**
```bash
poetry run pytest tests/unit/ -v
```

**Run only integration tests:**
```bash
poetry run pytest tests/integration/ -v
```

**Run with coverage report:**
```bash
poetry run pytest --cov=gdpr_pseudonymizer --cov-report=term-missing --cov-report=html
```

**Run validation workflow integration tests specifically:**
```bash
poetry run pytest tests/integration/test_validation_workflow_integration.py -v
```

**Run quality checks:**
```bash
# Code formatting check
poetry run black --check gdpr_pseudonymizer tests

# Format code automatically
poetry run black gdpr_pseudonymizer tests

# Linting check
poetry run ruff check gdpr_pseudonymizer tests

# Type checking
poetry run mypy gdpr_pseudonymizer
```

**Run Windows-safe tests only (excludes spaCy-dependent tests):**
```bash
# Run non-spaCy unit tests (follows Windows CI pattern)
poetry run pytest tests/unit/test_benchmark_nlp.py tests/unit/test_config_manager.py tests/unit/test_data_models.py tests/unit/test_file_handler.py tests/unit/test_logger.py tests/unit/test_naive_processor.py tests/unit/test_name_dictionary.py tests/unit/test_process_command.py tests/unit/test_project_config.py tests/unit/test_regex_matcher.py tests/unit/test_validation_models.py tests/unit/test_validation_stub.py -v

# Run validation workflow integration tests (Windows-safe)
poetry run pytest tests/integration/test_validation_workflow_integration.py -v
```

### Test Coverage

- **Unit tests:** 34 tests for validation models, UI components, and workflow logic
- **Integration tests:** 19 tests for end-to-end validation workflow (Story 2.0.1 - Complete)
- **Current coverage:** 80.49% for validation module (combined unit + integration)
- **CI/CD:** Tests run on Python 3.9-3.11 across Windows, macOS, and Linux
- **Quality gates:** All pass (Black, Ruff, mypy, pytest)

### Key Integration Test Scenarios

The validation workflow integration tests cover:
- âœ… Full workflow: entity detection â†’ summary â†’ review â†’ confirmation
- âœ… User actions: confirm (Space), reject (R), modify (E), add entity (A), change pseudonym (C), context cycling (X)
- âœ… State transitions: PENDING â†’ CONFIRMED/REJECTED/MODIFIED
- âœ… Entity deduplication with grouped review
- âœ… Edge cases: empty documents, large documents (320+ entities), Ctrl+C interruption, invalid input
- âœ… Batch operations: Accept All Type (Shift+A), Reject All Type (Shift+R) with confirmation prompts
- âœ… Mock user input: Full simulation of keyboard interactions and prompts

---

## ğŸ“Š Project Metrics (As of 2026-01-25)

| Metric | Value | Status |
|--------|-------|--------|
| **Development Progress** | Week 6/14 | ğŸ”„ Epic 2 In Progress |
| **Stories Complete** | 13 (Epic 1 + Stories 2.0.1-2.3) | âœ… Epic 1 + 4 Epic 2 Stories |
| **Test Corpus Size** | 25 docs, 1,855 entities | âœ… Complete |
| **NLP Accuracy (Baseline)** | 29.5% F1 (spaCy) | âœ… Measured |
| **Hybrid Accuracy (NLP+Regex)** | 35.3% F1 (+52.2% PERSON) | âœ… Story 1.8 Complete |
| **Final Accuracy (AI+Human)** | 100% (validated) | ğŸ¯ By Design |
| **Pseudonym Libraries** | 3 themes (2,426 names total) | âœ… Story 2.1 Complete |
| **Compositional Matching** | Operational (component reuse + title stripping + compound names) | âœ… Stories 2.2, 2.3 Complete |
| **Validation UI** | Operational with deduplication | âœ… Stories 1.7, 1.9 Complete |
| **Validation Time** | <2 min (20-30 entities), <5 min (100 entities) | âœ… Targets Met |
| **Test Coverage** | 431 tests, 86%+ coverage | âœ… Stories 2.0.1-2.3 Complete |
| **Quality Gates** | Black, Ruff, mypy, pytest | âœ… All Pass |
| **Supported Languages** | French | ğŸ‡«ğŸ‡· v1.0 only |
| **Supported Formats** | .txt, .md | ğŸ“ v1.0 scope |

---

## ğŸ”— Quick Links

- ğŸ“˜ [Full PRD](docs/.ignore/prd.md) - Complete product requirements
- ğŸ“Š [Benchmark Report](docs/nlp-benchmark-report.md) - NLP accuracy analysis
- ğŸ¨ [Positioning Strategy](docs/positioning-messaging-v2-assisted.md) - Marketing & messaging
- ğŸ—ï¸ [Architecture Docs](docs/architecture/) - Technical design
- ğŸ“‹ [Approval Checklist](docs/PM-APPROVAL-CHECKLIST.md) - PM decision tracker

---

**Last Updated:** 2026-01-27 (Story 2.3 complete: French name preprocessing with title stripping and compound name handling, 53 tests, 94.64% coverage, QA score 100/100)

**Current Focus:** Epic 2 - Core Pseudonymization Engine (Week 6-10)
