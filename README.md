> üá¨üáß **English** | üá´üá∑ [Fran√ßais](README.fr.md)

# GDPR Pseudonymizer

[![PyPI version](https://img.shields.io/pypi/v/gdpr-pseudonymizer)](https://pypi.org/project/gdpr-pseudonymizer/)
[![Python versions](https://img.shields.io/pypi/pyversions/gdpr-pseudonymizer)](https://pypi.org/project/gdpr-pseudonymizer/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![CI](https://github.com/LioChanDaYo/RGPDpseudonymizer/actions/workflows/ci.yaml/badge.svg)](https://github.com/LioChanDaYo/RGPDpseudonymizer/actions/workflows/ci.yaml)
[![Docs](https://img.shields.io/badge/docs-GitHub%20Pages-blue)](https://liochandayo.github.io/RGPDpseudonymizer/)

**AI-Assisted Pseudonymization for French Documents with Human Verification**

Transform sensitive French documents for safe AI analysis with local processing, mandatory human review, and GDPR compliance.

---

## What's New in v1.1

- **GDPR Article 17 Right to Erasure** ‚Äî `delete-mapping` and `list-entities` commands for selective entity deletion with audit trail
- **Gender-aware pseudonym assignment** ‚Äî 945-name French dictionary automatically matches pseudonym gender to detected name gender
- **NER accuracy doubled** ‚Äî F1 score improved from 29.74% to 59.97% (+30.23pp) via annotation cleanup, regex expansion, and geography dictionary
- **PDF/DOCX input support** ‚Äî Process PDF and DOCX files directly: `pip install gdpr-pseudonymizer[formats]`
- **French documentation** ‚Äî Full French translation of README and user guides, MkDocs FR/EN toggle
- **Validation UI improvements** ‚Äî Context cycling dot indicator, batch feedback with entity counts, CI benchmark regression gate

**Upgrade:** `pip install --upgrade gdpr-pseudonymizer`

---

## üéØ Overview

GDPR Pseudonymizer is a **privacy-first tool** that combines AI efficiency with human accuracy to pseudonymize French text documents. Available as a **CLI tool** and a **desktop GUI** (v2.0 in development). Unlike fully automatic tools or cloud services, we prioritize **zero false negatives** and **legal defensibility** through mandatory validation workflows.

**Perfect for:**
- üèõÔ∏è **Privacy-conscious organizations** needing GDPR-compliant AI analysis
- üéì **Academic researchers** with ethics board requirements
- ‚öñÔ∏è **Legal/HR teams** requiring defensible pseudonymization
- ü§ñ **LLM users** who want to analyze confidential documents safely

---

## ‚ú® Key Features

### üîí **Privacy-First Architecture**
- ‚úÖ **100% local processing** - Your data never leaves your machine
- ‚úÖ **No cloud dependencies** - Works completely offline after installation
- ‚úÖ **Encrypted mapping tables** - AES-256-SIV encryption with PBKDF2 key derivation (210K iterations), passphrase-protected reversible pseudonymization
- ‚úÖ **Zero telemetry** - No analytics, crash reporting, or external communication

### ü§ù **AI + Human Verification**
- ‚úÖ **Hybrid detection** - AI pre-detects ~60% of entities (NLP + regex + geography dictionary)
- ‚úÖ **Mandatory validation** - You review and confirm all entities (ensures 100% accuracy)
- ‚úÖ **Fast validation UI** - Rich CLI interface with keyboard shortcuts, <2 min per document
- ‚úÖ **Smart workflow** - Entity-by-type grouping (PERSON ‚Üí ORG ‚Üí LOCATION) with context display
- ‚úÖ **Entity variant grouping** - Related forms ("Marie Dubois", "Pr. Dubois", "Dubois") merged into one validation item with "Also appears as:" display
- ‚úÖ **Batch actions** - Confirm/reject multiple entities efficiently

### üìä **Batch Processing**
- ‚úÖ **Consistent pseudonyms** - Same entity = same pseudonym across 10-100+ documents
- ‚úÖ **Compositional matching** - "Marie Dubois" ‚Üí "Leia Organa", "Marie" alone ‚Üí "Leia"
- ‚úÖ **Smart name handling** - Title stripping ("Dr. Marie Dubois" = "Marie Dubois"), compound names ("Jean-Pierre" treated as atomic)
- ‚úÖ **Selective entity processing** - `--entity-types` flag to filter by type (e.g., `--entity-types PERSON,LOCATION`)
- ‚úÖ **50%+ time savings** vs manual redaction (AI pre-detection + validation)

### üé≠ **Themed Pseudonyms**
- ‚úÖ **Readable output** - Star Wars, LOTR, or generic French names
- ‚úÖ **Maintains context** - LLM analysis preserves 85% document utility (validated: 4.27/5.0)
- ‚úÖ **Gender-aware** - Auto-detects French first name gender from 945-name dictionary and assigns gender-matched pseudonyms (female names ‚Üí female pseudonyms, male names ‚Üí male pseudonyms)
- ‚úÖ **Full entity support** - PERSON, LOCATION, and ORGANIZATION pseudonyms for all themes

---

## üöÄ Quick Start

**Status:** üéâ **v1.1.0** (February 2026)

### Realistic Expectations for v1.1

**What v1.1 delivers:**
- ü§ñ **AI-assisted detection** ‚Äî Hybrid NLP + regex detects ~60% of entities automatically (F1 59.97%)
- ‚úÖ **Mandatory human verification** ‚Äî You review and confirm all entities (2-3 min per document)
- üîí **100% accuracy guarantee** ‚Äî Human validation ensures zero false negatives
- ‚ö° **50%+ faster than manual** ‚Äî Pre-detection saves time vs pure manual redaction
- üóëÔ∏è **GDPR Article 17 erasure** ‚Äî Selectively delete entity mappings with audit trail
- üìÑ **PDF/DOCX support** ‚Äî Process PDF and DOCX files directly (optional extras)
- üá´üá∑ **French documentation** ‚Äî Full French translation of docs and user guides

**What v1.1 does NOT deliver:**
- ‚ùå Fully automatic "set and forget" processing
- ‚ùå 85%+ AI accuracy (current: ~60% F1 with hybrid approach)
- ‚ùå Optional validation mode (validation is mandatory)

### Roadmap

**v1.0 (MVP - Q1 2026):** AI-assisted CLI with mandatory validation
- Target: Privacy-conscious early adopters who value human oversight
- 100% local processing, encrypted mapping tables, audit trails

**v1.1 (Q1 2026) ‚Äî CURRENT RELEASE:**
- ‚úÖ GDPR Right to Erasure: selective entity deletion (`delete-mapping` command, Article 17)
- ‚úÖ Gender-aware pseudonym assignment for French names (945-name dictionary)
- ‚úÖ NER accuracy improvements: F1 29.74% ‚Üí 59.97% (+30.23pp)
- ‚úÖ French documentation translation (MkDocs i18n, 6 docs translated)
- ‚úÖ PDF/DOCX input format support (optional extras, text extraction)
- ‚úÖ CLI polish & minor enhancements (context cycling indicator, batch feedback, CI benchmarks)

**v2.0 (Q3-Q4 2026):** GUI & broader accessibility
- Desktop GUI wrapping CLI core (drag-and-drop, visual entity review)
- Standalone executables (.exe for Windows, .app for macOS) ‚Äî no Python required
- ‚úÖ French-first UI with i18n architecture (multi-language ready) ‚Äî **implemented in Story 6.6**
- WCAG AA accessibility for professional/academic contexts
- Target: Non-technical users (HR, legal, compliance teams)

**v3.0 (2027+):** NLP accuracy & automation
- Fine-tuned French NER model (70-85% F1 target, up from ~60%)
- Optional `--no-validate` flag for high-confidence workflows
- Confidence-based auto-processing (85%+ F1 target)
- Multi-language support (English, Spanish, German)

---

## ‚öôÔ∏è Installation

See [Installation Guide](https://liochandayo.github.io/RGPDpseudonymizer/installation/) for detailed platform-specific instructions.

### Prerequisites
- **Python 3.10, 3.11, or 3.12** (validated in CI/CD ‚Äî 3.13+ not yet tested)

### Install from PyPI (Recommended)

```bash
pip install gdpr-pseudonymizer

# Verify installation
gdpr-pseudo --help
```

> **Note:** The spaCy French model (~571MB) downloads automatically on first use. To pre-download it:
> ```bash
> python -m spacy download fr_core_news_lg
> ```

### Install from Source (Developer)

```bash
# Clone repository
git clone https://github.com/LioChanDaYo/RGPDpseudonymizer.git
cd RGPDpseudonymizer

# Install dependencies via Poetry
pip install poetry>=1.7.0
poetry install

# Verify installation
poetry run gdpr-pseudo --help
```

> **Note:** The spaCy French model (~571MB) downloads automatically on first use. To pre-download it:
> ```bash
> poetry run python -m spacy download fr_core_news_lg
> ```

### Quick Test

```bash
# Test on sample document
echo "Marie Dubois travaille √† Paris pour Acme SA." > test.txt
gdpr-pseudo process test.txt

# Or specify custom output file
gdpr-pseudo process test.txt -o output.txt
```

Expected output: "Leia Organa travaille √† Coruscant pour Rebel Alliance."

### Configuration File (Optional)

Generate a config template to customize default settings:

```bash
# Generate .gdpr-pseudo.yaml template in current directory
poetry run gdpr-pseudo config --init

# View current effective configuration
poetry run gdpr-pseudo config
```

Example `.gdpr-pseudo.yaml`:
```yaml
database:
  path: mappings.db

pseudonymization:
  theme: star_wars    # neutral, star_wars, lotr
  model: spacy

batch:
  workers: 4          # 1-8 (use 1 for interactive validation)
  output_dir: null

logging:
  level: INFO
```

**Note:** Passphrase is never stored in config files (security). Use `GDPR_PSEUDO_PASSPHRASE` env var or interactive prompt. Minimum 12 characters required (NFR12).

---

## üìñ Documentation

**Documentation Site:** [https://liochandayo.github.io/RGPDpseudonymizer/](https://liochandayo.github.io/RGPDpseudonymizer/)

**For Users:**
- üìò [Installation Guide](docs/installation.md) - Platform-specific installation instructions
- üìó [Usage Tutorial](docs/tutorial.md) - Step-by-step usage tutorials
- üìï [CLI Reference](docs/CLI-REFERENCE.md) - Complete command documentation
- üìï [Methodology & Academic Citation](docs/methodology.md) - Technical approach and GDPR compliance
- ‚ùì [FAQ](docs/faq.md) - Common questions and answers
- üîß [Troubleshooting](docs/troubleshooting.md) - Error reference and solutions

**For Developers:**
- üìö [API Reference](docs/api-reference.md) - Module documentation and extension points
- üèóÔ∏è [Architecture Documentation](docs/architecture/) - Technical design
- üìä [NLP Benchmark Report](docs/nlp-benchmark-report.md) - NER accuracy analysis
- üìä [Performance Report](docs/qa/performance-stability-report.md) - NFR performance validation results

**For Stakeholders:**
- üé® [Positioning & Messaging](docs/positioning-messaging-v2-assisted.md)
- üìã [Deliverables Summary](docs/DELIVERABLES-SUMMARY-2026-01-16.md)

---

## üåê Language Support

The GUI and CLI are available in **French** (default) and **English**, with live language switching.

### GUI Language Switching

Select your language in **Settings > Appearance > Language**. The change takes effect immediately ‚Äî no restart required.

### CLI Language

```bash
# French help (default on French systems)
gdpr-pseudo --lang fr --help

# English help (default on non-French systems)
gdpr-pseudo --lang en --help

# Via environment variable
GDPR_PSEUDO_LANG=fr gdpr-pseudo --help
```

**Language detection priority:**
1. `--lang` flag (explicit)
2. `GDPR_PSEUDO_LANG` environment variable
3. System locale auto-detection
4. English (CLI default) / French (GUI default)

---

## üî¨ Technical Details

### NLP Library Selection (Story 1.2 - Completed)

After comprehensive benchmarking on 25 French interview/business documents (1,737 annotated entities):

| Approach | F1 Score | Precision | Recall | Notes |
|----------|----------|-----------|--------|-------|
| **spaCy only** `fr_core_news_lg` | 29.5% | 27.0% | 32.7% | Story 1.2 baseline |
| **Hybrid** (spaCy + regex) | 59.97% | 48.17% | 79.45% | Story 5.3 (current) |

**Accuracy trajectory:** spaCy-only baseline ‚Üí hybrid approach with annotation cleanup, expanded regex patterns, and French geography dictionary doubled F1 score. PERSON recall reached 82.93%.

**Approved Solution:**
- ‚úÖ **Hybrid approach** (NLP + regex + geography dictionary) achieves ~60% F1
- ‚úÖ **Mandatory validation** ensures 100% final accuracy
- üìÖ **Fine-tuning** deferred to v3.0 (70-85% F1 target, requires training data from v1.x/v2.x user validations)

See full analysis: [docs/qa/ner-accuracy-report.md](docs/qa/ner-accuracy-report.md) | Historical baseline: [docs/nlp-benchmark-report.md](docs/nlp-benchmark-report.md)

### Validation Workflow (Story 1.7 - Complete)

The validation UI provides an intuitive keyboard-driven interface for reviewing detected entities:

**Features:**
- ‚úÖ **Entity-by-type grouping** - Review PERSON ‚Üí ORG ‚Üí LOCATION in logical order
- ‚úÖ **Context display** - See 10 words before/after each entity with highlighting
- ‚úÖ **Confidence scores** - Color-coded confidence from spaCy NER (green >80%, yellow 60-80%, red <60%)
- ‚úÖ **Keyboard shortcuts** - Single-key actions: [Space] Confirm, [R] Reject, [E] Modify, [A] Add, [C] Change pseudonym
- ‚úÖ **Batch operations** - Accept/reject all entities of a type at once (Shift+A/R) with entity count feedback
- ‚úÖ **Context cycling indicator** - Dot indicator (`‚óè ‚óã ‚óã ‚óã ‚óã`) shows current context position; `[Press X to cycle]` hint improves discoverability
- ‚úÖ **Help overlay** - Press [H] for full command reference
- ‚úÖ **Performance** - <2 minutes for typical 20-30 entity documents

**Workflow Steps:**
1. Summary screen (entity counts by type)
2. Review entities by type with context
3. Flag ambiguous entities for careful review
4. Final confirmation with summary of changes
5. Process document with validated entities

**Deduplication Feature (Story 1.9):** Duplicate entities grouped together - validate once, apply to all occurrences (66% time reduction for large docs)

**Entity Variant Grouping (Story 4.6):** Related entity forms automatically merged into single validation items. "Marie Dubois", "Pr. Dubois", and "Dubois" appear as one item with "Also appears as:" showing variant forms. Prevents Union-Find transitive bridging for ambiguous surnames shared by different people.

---

### Technology Stack

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| **Runtime** | Python | 3.10-3.12 | Validated in CI/CD (3.13+ not yet tested) |
| **NLP Library** | spaCy | 3.8.0 | French entity detection (fr_core_news_lg) |
| **CLI Framework** | Typer | 0.9+ | Command-line interface |
| **Database** | SQLite | 3.35+ | Local mapping table storage with WAL mode |
| **Encryption** | cryptography (AESSIV) | 44.0+ | AES-256-SIV encryption for sensitive fields (PBKDF2 key derivation, passphrase-protected) |
| **ORM** | SQLAlchemy | 2.0+ | Database abstraction and session management |
| **Desktop GUI** | PySide6 | 6.7+ | Desktop application (optional: `pip install gdpr-pseudonymizer[gui]`) |
| **Validation UI** | rich | 13.7+ | Interactive CLI entity review |
| **Keyboard Input** | readchar | 4.2+ | Single-keypress capture for validation UI |
| **Testing** | pytest | 7.4+ | Unit & integration testing |
| **CI/CD** | GitHub Actions | N/A | Automated testing (Windows/Mac/Linux) |

---

## ü§î Why AI-Assisted Instead of Automatic?

**Short answer:** Privacy and compliance require human oversight.

**Long answer:**
1. **GDPR defensibility** - Human verification provides legal audit trail
2. **Zero false negatives** - AI misses entities, humans catch them (100% coverage)
3. **Current NLP limitations** - French models on interview/business docs: 29.5% F1 out-of-box (hybrid approach reaches ~60%)
4. **Better than alternatives:**
   - ‚úÖ **vs Manual redaction:** 50%+ faster (AI pre-detection)
   - ‚úÖ **vs Cloud services:** 100% local processing (no data leakage)
   - ‚úÖ **vs Fully automatic tools:** 100% accuracy (human verification)

**User Perspective:**
> "I WANT human review for compliance reasons. The AI saves me time by pre-flagging entities, but I control the final decision." - Compliance Officer

---

## üéØ Use Cases

### 1. **Research Ethics Compliance**
**Scenario:** Academic researcher with 50 interview transcripts needing IRB approval

**Without GDPR Pseudonymizer:**
- ‚ùå Manual redaction: 16-25 hours
- ‚ùå Destroys document coherence for analysis
- ‚ùå Error-prone (human fatigue)

**With GDPR Pseudonymizer:**
- ‚úÖ AI pre-detection: ~30 min processing
- ‚úÖ Human validation: ~90 min review (50 docs √ó ~2 min each)
- ‚úÖ Total: **2-3 hours** (85%+ time savings)
- ‚úÖ Audit trail for ethics board

---

### 2. **HR Document Analysis**
**Scenario:** HR team analyzing employee feedback with ChatGPT

**Without GDPR Pseudonymizer:**
- ‚ùå Can't use ChatGPT (GDPR violation - employee names exposed)
- ‚ùå Manual analysis only (slow, limited insights)

**With GDPR Pseudonymizer:**
- ‚úÖ Pseudonymize locally (employee names ‚Üí pseudonyms)
- ‚úÖ Send to ChatGPT safely (no personal data exposed)
- ‚úÖ Get AI insights while staying GDPR-compliant

---

### 3. **Legal Document Preparation**
**Scenario:** Law firm preparing case materials for AI legal research

**Without GDPR Pseudonymizer:**
- ‚ùå Cloud pseudonymization service (third-party risk)
- ‚ùå Manual redaction (expensive billable hours)

**With GDPR Pseudonymizer:**
- ‚úÖ 100% local processing (client confidentiality)
- ‚úÖ Human-verified accuracy (legal defensibility)
- ‚úÖ Reversible mappings (can de-pseudonymize if needed)

---

## ‚öñÔ∏è GDPR Compliance

### How GDPR Pseudonymizer Supports Compliance

| GDPR Requirement | Implementation |
|------------------|----------------|
| **Art. 25 - Data Protection by Design** | Local processing, no cloud dependencies, encrypted storage |
| **Art. 30 - Processing Records** | Comprehensive audit logs (Story 2.5): operations table tracks timestamp, files processed, entity count, model version, theme, success/failure, processing time; JSON/CSV export for compliance reporting |
| **Art. 32 - Security Measures** | AES-256-SIV encryption with PBKDF2 key derivation (210,000 iterations), passphrase-protected storage, column-level encryption for sensitive fields |
| **Art. 35 - Privacy Impact Assessment** | Transparent methodology, cite-able approach for DPIA documentation |
| **Recital 26 - Pseudonymization** | Consistent pseudonym mapping, reversibility with passphrase |

### What Pseudonymization Means (Legally)

**According to GDPR Article 4(5):**
> "Pseudonymization means the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject **without the use of additional information**, provided that such additional information is kept separately."

**GDPR Pseudonymizer approach:**
- ‚úÖ **Personal data replaced:** Names, locations, organizations ‚Üí pseudonyms
- ‚úÖ **Separate storage:** Mapping table encrypted with passphrase (separate from documents)
- ‚úÖ **Reversibility:** Authorized users can de-pseudonymize with passphrase
- ‚ö†Ô∏è **Note:** Pseudonymization reduces risk but **does NOT make data anonymous**

**Recommendation:** Consult your Data Protection Officer (DPO) for specific compliance guidance.

---

## üõ†Ô∏è Development Status

**Epics 1-5 Complete** ‚Äî v1.1.0 (February 2026). **Epic 6 in progress** ‚Äî v2.0 Desktop GUI.

- ‚úÖ **Epic 1:** Foundation & NLP Validation (9 stories) ‚Äî spaCy integration, validation UI, hybrid detection, entity deduplication
- ‚úÖ **Epic 2:** Core Pseudonymization Engine (9 stories) ‚Äî pseudonym libraries, encryption, audit logging, batch processing, GDPR 1:1 mapping
- ‚úÖ **Epic 3:** CLI Interface & Batch Processing (7 stories) ‚Äî 8 CLI commands, progress reporting, config files, parallel batch, UX polish
- ‚úÖ **Epic 4:** Launch Readiness (8 stories) ‚Äî LLM utility validation, cross-platform testing, documentation, NER accuracy suite, performance validation, beta feedback integration, codebase refactoring, launch preparation
- ‚úÖ **Epic 5:** Quick Wins & GDPR Compliance (7 stories) ‚Äî GDPR Article 17 erasure, gender-aware pseudonyms, NER accuracy improvements (F1 29.74% ‚Üí 59.97%), French documentation translation, PDF/DOCX support, CLI polish & benchmarks, v1.1 release
- üöß **Epic 6:** v2.0 Desktop GUI & Broader Accessibility (9 stories) ‚Äî PySide6 desktop application, visual entity validation, batch GUI, i18n, WCAG AA, standalone executables
  - ‚úÖ Story 6.1: UX Architecture & GUI Framework Selection
  - ‚úÖ Story 6.2: GUI Application Foundation (main window, theming, home screen, settings, 77 GUI tests)
  - ‚úÖ Story 6.3: Document Processing Workflow (passphrase dialog, processing worker, results screen, 45 new GUI tests)
  - ‚úÖ Story 6.4: Visual Entity Validation Interface (entity editor, entity panel, validation state with undo/redo, 72 new GUI tests)
  - ‚úÖ Story 6.5: Batch Processing & Configuration Management (batch screen, database management, settings enhancements, 40 new tests)
  - ‚úÖ Story 6.6: Internationalization & French UI (dual-track i18n: Qt Linguist + gettext, 267 GUI strings, ~50 CLI strings, live language switching, 53 new tests)
- **Total:** 46 stories, 1418+ tests, 86%+ coverage, all quality gates green

---

## ü§ù Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for details on:
- Bug reports and feature requests
- Development setup and code quality requirements
- PR process and commit message format

Please read our [Code of Conduct](CODE_OF_CONDUCT.md) before participating.

---

## üìß Contact & Support

**Project Lead:** Lionel Deveaux - [@LioChanDaYo](https://github.com/LioChanDaYo)

**For questions and support:**
- üí¨ [GitHub Discussions](https://github.com/LioChanDaYo/RGPDpseudonymizer/discussions) ‚Äî General questions, use cases
- üêõ [GitHub Issues](https://github.com/LioChanDaYo/RGPDpseudonymizer/issues) ‚Äî Bug reports, feature requests
- üìñ [SUPPORT.md](SUPPORT.md) ‚Äî Full support process and self-help checklist

---

## üìú License

This project is licensed under the [MIT License](LICENSE).

---

## üôè Acknowledgments

**Built with:**
- [spaCy](https://spacy.io/) - Industrial-strength NLP library
- [Typer](https://typer.tiangolo.com/) - Modern CLI framework
- [rich](https://rich.readthedocs.io/) - Beautiful CLI formatting

**Inspired by:**
- GDPR privacy-by-design principles
- Academic research ethics requirements
- Real-world need for safe AI document analysis

**Methodology:**
- Developed using [BMAD-METHOD‚Ñ¢](https://bmad.ai) framework
- Interactive elicitation and multi-perspective validation

---

## ‚ö†Ô∏è Disclaimer

**GDPR Pseudonymizer is a tool to assist with GDPR compliance. It does NOT provide legal advice.**

**Important notes:**
- ‚ö†Ô∏è Pseudonymization reduces risk but is NOT anonymization
- ‚ö†Ô∏è You remain the data controller under GDPR
- ‚ö†Ô∏è Consult your DPO or legal counsel for compliance guidance
- ‚ö†Ô∏è Human validation is MANDATORY - do not skip review steps
- ‚ö†Ô∏è Test thoroughly before production use

**Current limitations:**
- AI detection: ~60% F1 baseline (not 85%+)
- Validation required for ALL documents (not optional)
- French documents only (English, Spanish, etc. in future versions)
- Text-based formats: .txt, .md, .pdf, .docx (PDF/DOCX require optional extras: `pip install gdpr-pseudonymizer[formats]`)

---

## üß™ Testing

### Running Tests

The project includes comprehensive unit and integration tests covering the validation workflow, NLP detection, and core functionality.

**Note for Windows users:** Due to known spaCy access violations on Windows ([spaCy issue #12659](https://github.com/explosion/spaCy/issues/12659)), Windows CI runs non-spaCy tests only. Full test suite runs on Linux/macOS.

**Run all tests:**
```bash
poetry run pytest -v
```

**Run only unit tests:**
```bash
poetry run pytest tests/unit/ -v
```

**Run only integration tests:**
```bash
poetry run pytest tests/integration/ -v
```

**Run accuracy validation tests (requires spaCy model):**
```bash
poetry run pytest tests/accuracy/ -v -m accuracy -s
```

**Run performance & stability tests (requires spaCy model):**
```bash
# All performance tests (stability, memory, startup, stress)
poetry run pytest tests/performance/ -v -s -p no:benchmark --timeout=600

# Benchmark tests only (pytest-benchmark)
poetry run pytest tests/performance/ --benchmark-only -v -s
```

**Run with coverage report:**
```bash
poetry run pytest --cov=gdpr_pseudonymizer --cov-report=term-missing --cov-report=html
```

**Run validation workflow integration tests specifically:**
```bash
poetry run pytest tests/integration/test_validation_workflow_integration.py -v
```

**Run quality checks:**
```bash
# Code formatting check
poetry run black --check gdpr_pseudonymizer tests

# Format code automatically
poetry run black gdpr_pseudonymizer tests

# Linting check
poetry run ruff check gdpr_pseudonymizer tests

# Type checking
poetry run mypy gdpr_pseudonymizer
```

**Run Windows-safe tests only (excludes spaCy-dependent tests):**
```bash
# Run non-spaCy unit tests (follows Windows CI pattern)
poetry run pytest tests/unit/test_benchmark_nlp.py tests/unit/test_config_manager.py tests/unit/test_data_models.py tests/unit/test_file_handler.py tests/unit/test_logger.py tests/unit/test_naive_processor.py tests/unit/test_name_dictionary.py tests/unit/test_process_command.py tests/unit/test_project_config.py tests/unit/test_regex_matcher.py tests/unit/test_validation_models.py tests/unit/test_validation_stub.py -v

# Run validation workflow integration tests (Windows-safe)
poetry run pytest tests/integration/test_validation_workflow_integration.py -v
```

### Test Coverage

- **Unit tests:** 1030+ tests covering validation models, UI components, encryption, database operations, audit logging, progress tracking, gender detection, context cycling indicator, i18n (GUI + CLI), and core logic
- **Integration tests:** 90 tests for end-to-end workflows including validation (Story 2.0.1), encrypted database operations (Story 2.4), compositional logic, and hybrid detection
- **Accuracy tests:** 22 tests validating NER accuracy against 25-document ground-truth corpus (Story 4.4)
- **Performance tests:** 19 tests validating all NFR targets ‚Äî single-document benchmarks (NFR1), entity-detection benchmarks, batch performance (NFR2), memory profiling (NFR4), startup time (NFR5), stability/error rate (NFR6), stress testing (Story 4.5)
- **Current coverage:** 86%+ across all modules (100% for progress module, 91.41% for AuditRepository)
- **Total tests:** 1418+ tests
- **CI/CD:** Tests run on Python 3.10-3.12 across Windows, macOS, and Linux
- **Quality gates:** All pass (Black, Ruff, mypy, pytest)

### Key Integration Test Scenarios

The integration test suite covers:

**Validation Workflow (19 tests):**
- ‚úÖ Full workflow: entity detection ‚Üí summary ‚Üí review ‚Üí confirmation
- ‚úÖ User actions: confirm (Space), reject (R), modify (E), add entity (A), change pseudonym (C), context cycling (X)
- ‚úÖ State transitions: PENDING ‚Üí CONFIRMED/REJECTED/MODIFIED
- ‚úÖ Entity deduplication with grouped review
- ‚úÖ Edge cases: empty documents, large documents (320+ entities), Ctrl+C interruption, invalid input
- ‚úÖ Batch operations: Accept All Type (Shift+A), Reject All Type (Shift+R) with confirmation prompts
- ‚úÖ Mock user input: Full simulation of keyboard interactions and prompts

**Encrypted Database (9 tests):**
- ‚úÖ End-to-end workflow: init ‚Üí open ‚Üí save ‚Üí query ‚Üí close
- ‚úÖ Cross-session consistency: Same passphrase retrieves same data
- ‚úÖ Idempotency: Multiple queries return same results
- ‚úÖ Encrypted data at rest: Sensitive fields stored encrypted in SQLite
- ‚úÖ Compositional logic integration: Encrypted component queries
- ‚úÖ Repository integration: All repositories (mapping, audit, metadata) work with encrypted session
- ‚úÖ Concurrent reads: WAL mode enables multiple readers
- ‚úÖ Database indexes: Query performance optimization verified
- ‚úÖ Batch save rollback: Transaction integrity on errors

---

## üìä Project Metrics (As of 2026-02-20)

| Metric | Value | Status |
|--------|-------|--------|
| **Development Progress** | v2.0-dev | üöß Epic 6 in progress (Stories 6.1-6.6 complete) |
| **Stories Complete** | 46 (Epic 1-5 + 6.1-6.6) | ‚úÖ Epics 1-5, üöß Epic 6 |
| **LLM Utility (NFR10)** | 4.27/5.0 (85.4%) | ‚úÖ PASSED (threshold: 80%) |
| **Installation Success (NFR3)** | 87.5% (7/8 platforms) | ‚úÖ PASSED (threshold: 85%) |
| **First Pseudonymization (NFR14)** | 100% within 30 min | ‚úÖ PASSED (threshold: 80%) |
| **Critical Bugs Found** | 1 (Story 2.8) | ‚úÖ RESOLVED - Epic 3 Unblocked |
| **Test Corpus Size** | 25 docs, 1,737 entities | ‚úÖ Complete (post-cleanup) |
| **NLP Accuracy (Baseline)** | 29.5% F1 (spaCy only) | ‚úÖ Measured (Story 1.2) |
| **Hybrid Accuracy (NLP+Regex)** | 59.97% F1 (+30.23pp vs baseline) | ‚úÖ Story 5.3 Complete |
| **Final Accuracy (AI+Human)** | 100% (validated) | üéØ By Design |
| **Pseudonym Libraries** | 3 themes (2,426 names + 240 locations + 588 orgs) | ‚úÖ Stories 2.1, 3.0, 4.6 Complete |
| **Compositional Matching** | Operational (component reuse + title stripping + compound names) | ‚úÖ Stories 2.2, 2.3 Complete |
| **Batch Processing** | Architecture validated (multiprocessing.Pool, 1.17x-2.5x speedup) | ‚úÖ Story 2.7 Complete |
| **Encrypted Storage** | AES-256-SIV with passphrase protection (PBKDF2 210K iterations) | ‚úÖ Story 2.4 Complete |
| **Audit Logging** | GDPR Article 30 compliance (operations table + JSON/CSV export) | ‚úÖ Story 2.5 Complete |
| **Validation UI** | Operational with deduplication | ‚úÖ Stories 1.7, 1.9 Complete |
| **Validation Time** | <2 min (20-30 entities), <5 min (100 entities) | ‚úÖ Targets Met |
| **Single-Doc Performance (NFR1)** | ~6s mean for 3.5K words | ‚úÖ PASSED (<30s threshold, 80% headroom) |
| **Batch Performance (NFR2)** | ~5 min for 50 docs | ‚úÖ PASSED (<30min threshold, 83% headroom) |
| **Memory Usage (NFR4)** | ~1 GB Python-tracked peak | ‚úÖ PASSED (<8GB threshold) |
| **CLI Startup (NFR5)** | 0.56s (help), 6.0s (cold start w/ model) | ‚úÖ PASSED (<5s for CLI startup) |
| **Error Rate (NFR6)** | ~0% unexpected errors | ‚úÖ PASSED (<10% threshold) |
| **Test Coverage** | 1418+ tests (incl. 301 GUI), 86%+ coverage | ‚úÖ All Quality Checks Pass |
| **Quality Gates** | Ruff, mypy, pytest | ‚úÖ All Pass (0 issues) |
| **GUI/CLI Languages** | French (default), English | üåê Live switching (Story 6.6) |
| **Supported Document Languages** | French | üá´üá∑ v1.0 only |
| **Supported Formats** | .txt, .md, .pdf, .docx | üìù PDF/DOCX via optional extras |

---

## üîó Quick Links

- üìò [Full PRD](docs/.ignore/prd.md) - Complete product requirements
- üìä [Benchmark Report](docs/nlp-benchmark-report.md) - NLP accuracy analysis
- üé® [Positioning Strategy](docs/positioning-messaging-v2-assisted.md) - Marketing & messaging
- üèóÔ∏è [Architecture Docs](docs/architecture/) - Technical design
- üìã [Approval Checklist](docs/PM-APPROVAL-CHECKLIST.md) - PM decision tracker

---

**Last Updated:** 2026-02-23 (v2.0-dev ‚Äî Epic 6 Story 6.6 complete: internationalization & French UI, dual-track i18n with live language switching, 301 GUI tests, 1418+ total tests)
